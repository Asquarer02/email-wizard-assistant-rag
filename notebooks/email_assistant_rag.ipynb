{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b72145a",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5215a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d32398",
   "metadata": {},
   "source": [
    "# Load Environment Variables (for OpenAI API Key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78f8208",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"OPENAI_API_KEY not found in .env file. Please set it.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50fb3a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/proc_email.csv\" \n",
    "FAISS_INDEX_PATH = \"../faiss_index\" \n",
    "EMAIL_COUNT = 60 \n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 20\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-3-small\" \n",
    "LLM_MODEL_NAME = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28e74d6",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1984469c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: ../data/proc_email.csv\n",
      "Loaded 99 total emails.\n",
      "Selected 60 emails for processing.\n",
      "\n",
      "Sample document content (from 'to_index' column):\n",
      "To: frozenset({'robert.walker@enron.com'})\n",
      "From: frozenset({'daren.farmer@enron.com'})\n",
      "X-To: Robert Walker\n",
      "X-From: Daren J Farmer\n",
      "content: ENA Contact\n",
      "\n",
      "Daren Farmer\n",
      "Phone # 713-853-6905\n",
      "Fax# 713-646-2391\n",
      "\n",
      "EB3211F\n",
      "to_index: From Daren J Farmer to Robert Walker: ENA Contact\n",
      "\n",
      "Daren Farmer\n",
      "Phone # 713-853-6905\n",
      "Fax# 713-646-2391\n",
      "\n",
      "EB3211F...\n",
      "\n",
      "Sample document metadata (source): From Daren J Farmer to Robert Walker: ENA Contact\n",
      "\n",
      "Daren Farmer\n",
      "Phone # 713-853-6905\n",
      "Fax# 713-646-23...\n",
      "\n",
      "--- Text Splitting ---\n",
      "Split 60 documents into 188 chunks.\n",
      "Sample split chunk: To: frozenset({'robert.walker@enron.com'})\n",
      "From: frozenset({'daren.farmer@enron.com'})\n",
      "X-To: Robert Walker\n",
      "X-From: Daren J Farmer\n",
      "content: ENA Contact\n",
      "\n",
      "Daren Farmer\n",
      "Phone # 713-853-6905\n",
      "Fax# 713-646-2...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading data from: {DATA_PATH}\")\n",
    "\n",
    "loader = CSVLoader(file_path=DATA_PATH,\n",
    "                   encoding=\"utf8\",\n",
    "                   source_column=\"to_index\") \n",
    "\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} total emails.\") \n",
    "\n",
    "if len(documents) >= EMAIL_COUNT:\n",
    "    selected_documents = documents[:EMAIL_COUNT]\n",
    "    print(f\"Selected {len(selected_documents)} emails for processing.\")\n",
    "else:\n",
    "    selected_documents = documents\n",
    "    print(f\"Warning: Fewer than {EMAIL_COUNT} emails available. Using all {len(selected_documents)} loaded emails.\")\n",
    "\n",
    "if selected_documents:\n",
    "    print(\"\\nSample document content (from 'to_index' column):\")\n",
    "    \n",
    "    print(selected_documents[0].page_content[:500] + \"...\")\n",
    "    print(f\"\\nSample document metadata (source): {selected_documents[0].metadata['source'][:100]}...\")\n",
    "else:\n",
    "    print(\"No documents were loaded or selected. Exiting.\")\n",
    "    \n",
    "    \n",
    "print(\"\\n--- Text Splitting ---\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP\n",
    ")\n",
    "all_splits = text_splitter.split_documents(selected_documents)\n",
    "\n",
    "print(f\"Split {len(selected_documents)} documents into {len(all_splits)} chunks.\")\n",
    "if all_splits:\n",
    "    print(f\"Sample split chunk: {all_splits[0].page_content[:200]}...\")\n",
    "else:\n",
    "    print(\"No splits created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3105d03",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa42aabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized OpenAIEmbeddings with model: text-embedding-3-small\n",
      "Creating new FAISS index...\n",
      "FAISS index created and saved to: ../faiss_index\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL_NAME)\n",
    "print(f\"Initialized OpenAIEmbeddings with model: {EMBEDDING_MODEL_NAME}\")\n",
    "\n",
    "if os.path.exists(FAISS_INDEX_PATH) and os.listdir(FAISS_INDEX_PATH):\n",
    "    print(f\"Loading existing FAISS index from: {FAISS_INDEX_PATH}\")\n",
    "    try:\n",
    "        vector_store = FAISS.load_local(FAISS_INDEX_PATH, embeddings, allow_dangerous_deserialization=True)\n",
    "        print(\"FAISS index loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading FAISS index: {e}. Recreating index.\")\n",
    "        if all_splits:\n",
    "            print(\"Creating new FAISS index...\")\n",
    "            vector_store = FAISS.from_documents(documents=all_splits, embedding=embeddings)\n",
    "            vector_store.save_local(FAISS_INDEX_PATH)\n",
    "            print(f\"FAISS index created and saved to: {FAISS_INDEX_PATH}\")\n",
    "        else:\n",
    "            print(\"No document splits to create index from. Cannot proceed.\")\n",
    "            \n",
    "else:\n",
    "    if all_splits:\n",
    "        print(\"Creating new FAISS index...\")\n",
    "        vector_store = FAISS.from_documents(documents=all_splits, embedding=embeddings)\n",
    "        os.makedirs(FAISS_INDEX_PATH, exist_ok=True) \n",
    "        vector_store.save_local(FAISS_INDEX_PATH)\n",
    "        print(f\"FAISS index created and saved to: {FAISS_INDEX_PATH}\")\n",
    "    else:\n",
    "        print(\"No document splits to create index from. Cannot proceed with FAISS creation.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547bab79",
   "metadata": {},
   "source": [
    "# Retriever and QA Chain Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bb750ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever created from FAISS vector store (for QA chain).\n",
      "\n",
      "Testing FAISS similarity_search_with_score with query: 'What is the ENA contact information for Daren Farmer?'\n",
      "Retrieved 3 documents with scores.\n",
      "--- Document 1 (Score: 0.6297) ---\n",
      "To: frozenset({'robert.walker@enron.com'})\n",
      "From: frozenset({'daren.farmer@enron.com'})\n",
      "X-To: Robert Walker\n",
      "X-From: Daren J Farmer\n",
      "content: ENA Contact\n",
      "\n",
      "Daren Farmer\n",
      "Phone # 713-853-6905\n",
      "Fax# 713-646-2391\n",
      "\n",
      "EB3211F\n",
      "to_index: From Daren J Farmer to Robert Walker: ENA Contact\n",
      "\n",
      "Daren Farmer\n",
      "Phone # 713-8...\n",
      "(Source: From Daren J Farmer to Robert Walker: ENA Contact\n",
      "\n",
      "Daren Farmer\n",
      "Phone # 713-853-6905\n",
      "Fax# 713-646-23...)\n",
      "--------------------\n",
      "--- Document 2 (Score: 0.9362) ---\n",
      "Group-\n",
      "\n",
      "Earlier this week, we met Tana Jones (Senior Legal Specialist) and Leslie \n",
      "Hansen (Legal Counsel) with ENA (servicing ENW) to discuss the process for \n",
      "executing NDAs.  Leslie will serve as in-house legal counsel for EMS while \n",
      "Tana will be the Senior Legal Assistant for all documentation suc...\n",
      "(Source: From Tana Jones to Stephen Abbanat: ----- Forwarded by Tana Jones/HOU/ECT on 10/26/2000 02:22 PM ---...)\n",
      "--------------------\n",
      "--- Document 3 (Score: 0.9362) ---\n",
      "Group-\n",
      "\n",
      "Earlier this week, we met Tana Jones (Senior Legal Specialist) and Leslie \n",
      "Hansen (Legal Counsel) with ENA (servicing ENW) to discuss the process for \n",
      "executing NDAs.  Leslie will serve as in-house legal counsel for EMS while \n",
      "Tana will be the Senior Legal Assistant for all documentation suc...\n",
      "(Source: From Tana Jones to Stephen Abbanat: ----- Forwarded by Tana Jones/HOU/ECT on 10/26/2000 02:22 PM ---...)\n",
      "--------------------\n",
      "\n",
      "Initialized ChatOpenAI with model: gpt-4o-mini\n",
      "RAG QA chain created.\n"
     ]
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3}) \n",
    "print(\"Retriever created from FAISS vector store (for QA chain).\")\n",
    "sample_query_for_similarity_search = \"What is the ENA contact information for Daren Farmer?\"\n",
    "print(f\"\\nTesting FAISS similarity_search_with_score with query: '{sample_query_for_similarity_search}'\")\n",
    "docs_and_scores = vector_store.similarity_search_with_score(\n",
    "    query=sample_query_for_similarity_search,\n",
    "    k=3 \n",
    ")\n",
    "\n",
    "print(f\"Retrieved {len(docs_and_scores)} documents with scores.\")\n",
    "for i, (doc, score) in enumerate(docs_and_scores):\n",
    "    print(f\"--- Document {i+1} (Score: {score:.4f}) ---\") \n",
    "    print(doc.page_content[:300] + \"...\")\n",
    "    print(f\"(Source: {doc.metadata.get('source', 'N/A')[:100]}...)\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "llm = ChatOpenAI(model_name=LLM_MODEL_NAME, temperature=0.7)\n",
    "print(f\"\\nInitialized ChatOpenAI with model: {LLM_MODEL_NAME}\")\n",
    "\n",
    "prompt_template = \"\"\"You are an Email Wizard's Assistant. Use the following pieces of context, which are past emails, to answer the question at the end.\n",
    "If you don't know the answer from the context, just say that you don't know, don't try to make up an answer.\n",
    "Provide a concise answer, and if possible, quote relevant parts from the retrieved emails.\n",
    "If the question is a general greeting or not answerable from the emails, respond politely.\n",
    "Context:\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever, \n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs={\"prompt\": QA_PROMPT}\n",
    ")\n",
    "print(\"RAG QA chain created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829eecfc",
   "metadata": {},
   "source": [
    "# Testing RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "745f91c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Query: What is the phone number for Daren Farmer at ENA?\n",
      "\n",
      "LLM Answer:\n",
      "The phone number for Daren Farmer at ENA is 713-853-6905.\n",
      "\n",
      "\n",
      "Query: What is the discussion about i2 Technologies and Tax?\n",
      "\n",
      "LLM Answer:\n",
      "The discussion about i2 Technologies and Tax revolves around the approval of contracts related to Enron Credit.com. Tana Jones is seeking confirmation that Erica's legal advice, which expresses no problem with the agreement, should apply to not just the Non-Disclosure Agreement (NDA) in question, but also to all NDAs and the entire business originating from the Houston-based EnronCredit.com team. Tana states, \"Erica's advice needs to apply not only to this NDA, but probably all of the NDA's that are going to originate from the Houston based EnronCredit.com business team.\" Additionally, Mark Taylor emphasizes the need to confirm whether Tax has no issues with these contracts being signed in the U.S.\n",
      "\n",
      "\n",
      "Query: Who should be contacted about the MDEA Agreement scheduling?\n",
      "\n",
      "LLM Answer:\n",
      "The contact for the MDEA Agreement scheduling should be Bob Priest, as he is mentioned as available for a meeting early next week. Reagan Rorschach states, \"Bob is only available Monday,\" indicating he is a key person in this scheduling. Additionally, Marvin is also involved in the discussions.\n",
      "\n",
      "\n",
      "Query: Tell me about the Vitro/Termination agreement.\n",
      "\n",
      "LLM Answer:\n",
      "The context does not provide specific details about the Vitro/Termination agreement itself. However, it indicates that Kay Mann has not seen a signed copy of the termination agreement and is concerned about ensuring that the fully executed document has been processed. Kay mentioned in an email, \"I just want to make sure that the fully executed document has been processed.\" Additionally, Peggy Banczak requested copies of any GE contracts related to the agreement, stating, \"I have not received copies of any of the GE contracts.\" \n",
      "\n",
      "For more specific information about the contents or implications of the Vitro/Termination agreement, there is no available data in the emails.\n",
      "\n",
      "\n",
      "Query: What's the status of my project?\n",
      "\n",
      "LLM Answer:\n",
      "I'm sorry, but the context provided does not include any specific information about the status of your project.\n",
      "\n",
      "\n",
      "Query: Hi, how are you?\n",
      "\n",
      "LLM Answer:\n",
      "I'm sorry, but I don't have that information from the emails.\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "        \"What is the phone number for Daren Farmer at ENA?\",\n",
    "        \"What is the discussion about i2 Technologies and Tax?\",\n",
    "        \"Who should be contacted about the MDEA Agreement scheduling?\",\n",
    "        \"Tell me about the Vitro/Termination agreement.\",\n",
    "        \"What's the status of my project?\", \n",
    "        \"Hi, how are you?\" \n",
    "    ]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n\\nQuery: {query}\")\n",
    "    try:\n",
    "        result = qa_chain.invoke({\"query\": query})\n",
    "        print(\"\\nLLM Answer:\")\n",
    "        print(result[\"result\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing query '{query}': {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ca9a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
